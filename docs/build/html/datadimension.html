

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Examples of how things can go wrong &mdash; Relative clustering validation 0.0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Code description" href="code_description.html" />
    <link rel="prev" title="Performance on benchmark datasets" href="experiments.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> Relative clustering validation
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">User guide / Tutorial</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installing.html">Installing</a></li>
<li class="toctree-l1"><a class="reference internal" href="code_usage.html">How to use <code class="docutils literal notranslate"><span class="pre">reval</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="experiments.html">Performance on benchmark datasets</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Examples of how things can go wrong</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#number-of-features-when-enough-is-enough">Number of features: when enough is enough?</a></li>
<li class="toctree-l2"><a class="reference internal" href="#number-of-samples-too-few-not-good">Number of samples: too few, not good</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Code guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="code_description.html">Code description</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Relative clustering validation</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Examples of how things can go wrong</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/datadimension.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="examples-of-how-things-can-go-wrong">
<h1>Examples of how things can go wrong<a class="headerlink" href="#examples-of-how-things-can-go-wrong" title="Permalink to this headline">¶</a></h1>
<p>We discuss now typical situations that might happen when processing real-world datasets and
how these can modify <code class="docutils literal notranslate"><span class="pre">reval</span></code> performance. Code can be found in
<em>reval_clustering/working_examples/</em>, <code class="docutils literal notranslate"><span class="pre">data_dimensionality.py</span></code> file.</p>
<div class="section" id="number-of-features-when-enough-is-enough">
<h2>Number of features: when enough is enough?<a class="headerlink" href="#number-of-features-when-enough-is-enough" title="Permalink to this headline">¶</a></h2>
<p>With <code class="docutils literal notranslate"><span class="pre">make_blobs</span></code> function from <code class="docutils literal notranslate"><span class="pre">sklearn.datasets</span></code>, we generate a noisy dataset
(i.e., we set <code class="docutils literal notranslate"><span class="pre">cluster_std=5</span></code>) with 5 classes, 1,000 samples, and 10 features (see scatterplot below).
We partition it into training and test sets (30%) and we apply the relative validation algorithm with 10-fold cross-validation,
number of clusters ranging from 2 to 6, k-nearest neighbors and hierarchical clustering as classification
and clustering algorithms, respectively, and 100 iterations of random labeling.</p>
<img alt="_images/classes10.png" class="align-center" src="_images/classes10.png" />
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">reval.best_nclust_cv</span> <span class="kn">import</span> <span class="n">FindBestClustCV</span>
<span class="kn">from</span> <span class="nn">reval.visualization</span> <span class="kn">import</span> <span class="n">plot_metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">AgglomerativeClustering</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">adjusted_mutual_info_score</span><span class="p">,</span> <span class="n">zero_one_loss</span>
<span class="kn">from</span> <span class="nn">reval.relative_validation</span> <span class="kn">import</span> <span class="n">_kuhn_munkres_algorithm</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">data1</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow_r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;True labels for 10-feature dataset&#39;</span><span class="p">)</span>

<span class="n">X_tr</span><span class="p">,</span> <span class="n">X_ts</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">y_ts</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                          <span class="n">data1</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                          <span class="n">test_size</span><span class="o">=</span><span class="mf">0.30</span><span class="p">,</span>
                                          <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
                                          <span class="n">stratify</span><span class="o">=</span><span class="n">data1</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="c1"># Apply relative clustering validation with KNN and Hierarchical clustering</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">clustering</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">()</span>

<span class="n">findbestclust</span> <span class="o">=</span> <span class="n">FindBestClustCV</span><span class="p">(</span><span class="n">nfold</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                <span class="n">nclust_range</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
                                <span class="n">s</span><span class="o">=</span><span class="n">classifier</span><span class="p">,</span>
                                <span class="n">c</span><span class="o">=</span><span class="n">clustering</span><span class="p">,</span>
                                <span class="n">nrand</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">metrics</span><span class="p">,</span> <span class="n">nbest</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">findbestclust</span><span class="o">.</span><span class="n">best_nclust</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">findbestclust</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span> <span class="n">X_ts</span><span class="p">,</span> <span class="n">nbest</span><span class="p">)</span>

<span class="n">plot_metrics</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="s2">&quot;Reval performance for synthetic dataset with 10 features&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The algorithm selects 2 as the best clustering solution (see performance plot and scatterplot with predicted labels).</p>
<img alt="_images/performance10features.png" class="align-center" src="_images/performance10features.png" />
<img alt="_images/predlab10.png" class="align-center" src="_images/predlab10.png" />
<p>We now increase the number of features from 10 to 20 and reapply the relative validation algorithm with the same
parameters as before (see scatterplot with true labels below).</p>
<img alt="_images/classes20.png" class="align-center" src="_images/classes20.png" />
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">data2</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data2</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data2</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">data2</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow_r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;True labels for 20-feature dataset&#39;</span><span class="p">)</span>

<span class="n">X_tr</span><span class="p">,</span> <span class="n">X_ts</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">y_ts</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data2</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                          <span class="n">data2</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                          <span class="n">test_size</span><span class="o">=</span><span class="mf">0.30</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
                                          <span class="n">stratify</span><span class="o">=</span><span class="n">data2</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">findbestclust</span> <span class="o">=</span> <span class="n">FindBestClustCV</span><span class="p">(</span><span class="n">nfold</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">nclust_range</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
                                <span class="n">s</span><span class="o">=</span><span class="n">classifier</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">clustering</span><span class="p">,</span> <span class="n">nrand</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">metrics</span><span class="p">,</span> <span class="n">nbest</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">findbestclust</span><span class="o">.</span><span class="n">best_nclust</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">findbestclust</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span> <span class="n">X_ts</span><span class="p">,</span> <span class="n">nbest</span><span class="p">)</span>

<span class="n">plot_metrics</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="s2">&quot;Reval performance for synthetic dataset with 20 features&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_ts</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_ts</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">out</span><span class="o">.</span><span class="n">test_cllab</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow_r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Predicted labels for 20-feature dataset&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;AMI test set = </span><span class="si">{</span><span class="n">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">y_ts</span><span class="p">,</span> <span class="n">out</span><span class="o">.</span><span class="n">test_cllab</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">relabeling</span> <span class="o">=</span> <span class="n">_kuhn_munkres_algorithm</span><span class="p">(</span><span class="n">y_ts</span><span class="p">,</span> <span class="n">out</span><span class="o">.</span><span class="n">test_cllab</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;ACC test set = </span><span class="si">{</span><span class="mi">1</span> <span class="o">-</span> <span class="n">zero_one_loss</span><span class="p">(</span><span class="n">y_ts</span><span class="p">,</span> <span class="n">relabeling</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Because we increased the space volume, data become more sparse, but still preserving their group structure.
For this reason, now the algorithm is able to detect all 5 clusters. (See performance plot and scatterplot).</p>
<img alt="_images/performance20features.png" class="align-center" src="_images/performance20features.png" />
<img alt="_images/predlab20.png" class="align-center" src="_images/predlab20.png" />
<p>We use the
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_mutual_info_score.html#sklearn.metrics.adjusted_mutual_info_score">adjusted mutual information score (AMI)</a>
to account for the amount of information shared between true labels and clustering labels returned by the algorithm.
AMI returns 1 when two partitions are identical. Accuracy (ACC) is also used to compare the solutions after the
clustering labels have been permuted to match true labels.
On the test set, we obtain:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">AMI</span> <span class="o">=</span> <span class="mf">0.98</span><span class="p">;</span> <span class="n">ACC</span> <span class="o">=</span> <span class="mf">0.99</span>
</pre></div>
</div>
<p><strong>Remark</strong>: in situations where we are able to increase the number of features for a dataset,
it is important to remember the
<a class="reference external" href="https://en.wikipedia.org/wiki/Curse_of_dimensionality">curse of dimensionality</a>, i.e.,
the increase of the space dimension determines available data to become sparse and the number of samples required to
detect an effect to grow exponentially. For this reason, increasing the number of features might not help detect
dataset subgroups, because the data would become sparse, hence losing their structure.</p>
</div>
<div class="section" id="number-of-samples-too-few-not-good">
<h2>Number of samples: too few, not good<a class="headerlink" href="#number-of-samples-too-few-not-good" title="Permalink to this headline">¶</a></h2>
<p>In small datasets, that we suppose partitioned into groups, the number of samples is important to
an algorithm result. Too few samples, in fact, are usually not representative of data distributions and may
hinder clustering results. In the following, we randomly sample three groups from normal distributions
and we demonstrate how <code class="docutils literal notranslate"><span class="pre">reval</span></code> is able to identify the right number of subgroups only if the number of samples is
enough for subgroups with greater standard deviation to reliably represent the different distributions.</p>
<p>The first dataset generated comprises (see scatterplot):</p>
<ul class="simple">
<li><p>Group 1 (red): N = 100 random samples from normal distribution with m = -5; sd = 1</p></li>
<li><p>Group 2 (purple): N = 50 random samples from normal distribution with m = 12; sd = 2.5</p></li>
<li><p>Group 3 (green): N = 50 random samples from normal distribution with m = 6; sd = 2.5</p></li>
</ul>
<img alt="_images/classes1005050.png" class="align-center" src="_images/classes1005050.png" />
<p>We instantiate <code class="docutils literal notranslate"><span class="pre">FindBestClustCV()</span></code> class with 10-fold cross validation, k-nearest neighbors classifier and
hierarchical clustering, number of clusters ranging from 2 to 6, and 100 random labeling iterations.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set seed for reproducible examples</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># We generate three random samples from normal distributions</span>
<span class="n">data1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">data2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">data3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span> <span class="n">data2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">data3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">label</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">50</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="mi">50</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow_r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Random samples from normal distribution Ns=(100, 50, 50)&#39;</span><span class="p">)</span>

<span class="n">classifier</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">clustering</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">()</span>

<span class="n">X_tr</span><span class="p">,</span> <span class="n">X_ts</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">y_ts</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span>
                                          <span class="n">test_size</span><span class="o">=</span><span class="mf">0.30</span><span class="p">,</span>
                                          <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
                                          <span class="n">stratify</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="c1"># Apply relative clustering validation with KNN and Hierarchical clustering</span>
<span class="n">findbestclust</span> <span class="o">=</span> <span class="n">FindBestClustCV</span><span class="p">(</span><span class="n">nfold</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">nclust_range</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
                                <span class="n">s</span><span class="o">=</span><span class="n">classifier</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">clustering</span><span class="p">,</span> <span class="n">nrand</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">metrics</span><span class="p">,</span> <span class="n">nbest</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">findbestclust</span><span class="o">.</span><span class="n">best_nclust</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">findbestclust</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span> <span class="n">X_ts</span><span class="p">,</span> <span class="n">nbest</span><span class="p">)</span>
<span class="n">plot_metrics</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="s2">&quot;Reval performance for synthetic dataset with Ns=(100, 50, 50)&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_ts</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_ts</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">_kuhn_munkres_algorithm</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_ts</span><span class="p">),</span>
                                      <span class="n">out</span><span class="o">.</span><span class="n">test_cllab</span><span class="p">),</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow_r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Predicted labels for classes with Ns=(100, 50, 50)&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Result reports 2 as the best clustering solution (see performance plot and scatterplot). Groups 2 and 3, i.e., with
least number of subjects and higher standard deviation, are considered as a unique group by the algorithm.</p>
<img alt="_images/performance1005050.png" class="align-center" src="_images/performance1005050.png" />
<img alt="_images/predlab1005050.png" class="align-center" src="_images/predlab1005050.png" />
<p>To fix this, we try to increase the number of samples for groups 2 and 3 from 50 to 500 (see scatterplot)
and we rerun the algorithm with the same parameters.</p>
<img alt="_images/classes100500500.png" class="align-center" src="_images/classes100500500.png" />
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We now increase the number of samples in groups 2 and 3 to 500</span>
<span class="n">data1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">data2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">data3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data1</span><span class="p">,</span> <span class="n">data2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">data3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">label</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">500</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="mi">500</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow_r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Random samples from normal distribution Ns=(100, 500, 500)&#39;</span><span class="p">)</span>

<span class="n">classifier</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">clustering</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">()</span>

<span class="n">X_tr</span><span class="p">,</span> <span class="n">X_ts</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">y_ts</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span>
                                          <span class="n">test_size</span><span class="o">=</span><span class="mf">0.30</span><span class="p">,</span>
                                          <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
                                          <span class="n">stratify</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="c1"># Apply relative clustering validation with KNN and Hierarchical clustering</span>
<span class="n">findbestclust</span> <span class="o">=</span> <span class="n">FindBestClustCV</span><span class="p">(</span><span class="n">nfold</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">nclust_range</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
                                <span class="n">s</span><span class="o">=</span><span class="n">classifier</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">clustering</span><span class="p">,</span> <span class="n">nrand</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">metrics</span><span class="p">,</span> <span class="n">nbest</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">findbestclust</span><span class="o">.</span><span class="n">best_nclust</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">findbestclust</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span> <span class="n">X_ts</span><span class="p">,</span> <span class="n">nbest</span><span class="p">)</span>
<span class="n">plot_metrics</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="s2">&quot;Reval performance for synthetic dataset with Ns=(100, 500, 500)&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_ts</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_ts</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">y_ts</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow_r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Test set true labels for classes with Ns=(100, 500, 500)&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_ts</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_ts</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">_kuhn_munkres_algorithm</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_ts</span><span class="p">),</span>
                                      <span class="n">out</span><span class="o">.</span><span class="n">test_cllab</span><span class="p">),</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow_r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Predicted labels for classes with Ns=(100, 500, 500)&#39;</span><span class="p">)</span>

<span class="c1"># Performance scores</span>
<span class="c1"># Test set ACC</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Test set external &#39;</span>
      <span class="sa">f</span><span class="s1">&#39;ACC = </span><span class="si">{</span><span class="mi">1</span> <span class="o">-</span> <span class="n">zero_one_loss</span><span class="p">(</span><span class="n">y_ts</span><span class="p">,</span> <span class="n">_kuhn_munkres_algorithm</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_ts</span><span class="p">),</span> <span class="n">out</span><span class="o">.</span><span class="n">test_cllab</span><span class="p">))</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Validation stability metrics: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">][</span><span class="n">nbest</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test set model ACC = </span><span class="si">{</span><span class="n">out</span><span class="o">.</span><span class="n">test_acc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>This time the algorithm correctly identifies all three groups (see performance plot
and scaterplot with predicted labels).</p>
<img alt="_images/performance100500500.png" class="align-center" src="_images/performance100500500.png" />
<img alt="_images/predlab100500500.png" class="align-center" src="_images/predlab100500500.png" />
<p>To evaluate the algorithm performance we compute AMI and ACC between the true and <code class="docutils literal notranslate"><span class="pre">reval</span></code> partitions and report the
validation and testing metrics, i.e., normalized stability with 95% CI and testing accuracy, respectively.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">AMI</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">;</span> <span class="n">ACC</span> <span class="p">(</span><span class="n">external</span><span class="p">)</span> <span class="o">=</span> <span class="mf">0.93</span><span class="p">;</span> <span class="n">Normalized</span> <span class="n">stability</span><span class="p">:</span> <span class="mf">0.1</span> <span class="p">(</span><span class="mf">0.004</span><span class="p">;</span> <span class="mf">0.194</span><span class="p">);</span> <span class="n">ACC</span> <span class="o">=</span> <span class="mf">0.98</span>
</pre></div>
</div>
<p>Increasing the sampling size, the algorithm was able to correctly identify the three distributions.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="code_description.html" class="btn btn-neutral float-right" title="Code description" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="experiments.html" class="btn btn-neutral float-left" title="Performance on benchmark datasets" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Isotta Landi

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>