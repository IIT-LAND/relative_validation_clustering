

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Performance on benchmark datasets &mdash; Relative clustering validation 0.0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Examples of how things can go wrong" href="datadimension.html" />
    <link rel="prev" title="How to use reval" href="code_usage.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> Relative clustering validation
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">User guide / Tutorial</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installing.html">Installing</a></li>
<li class="toctree-l1"><a class="reference internal" href="code_usage.html">How to use <code class="docutils literal notranslate"><span class="pre">reval</span></code></a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Performance on benchmark datasets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#gaussian-blobs">Gaussian blobs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#gaussian-blobs-with-noise">Gaussian blobs with noise</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mnist-dataset">MNIST dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="#more-examples">More examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="datadimension.html">Examples of how things can go wrong</a></li>
</ul>
<p class="caption"><span class="caption-text">Code guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="code_description.html">Code description</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Relative clustering validation</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Performance on benchmark datasets</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/experiments.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="performance-on-benchmark-datasets">
<h1>Performance on benchmark datasets<a class="headerlink" href="#performance-on-benchmark-datasets" title="Permalink to this headline">¶</a></h1>
<p>We present here three examples to test <code class="docutils literal notranslate"><span class="pre">reval</span></code> performance. If
<a class="reference external" href="https://github.com/IIT-LAND/reval_clustering">github folder</a>
is cloned, code for the following experiments can be found in <em>reval_clustering/working_examples</em> folder.</p>
<ol class="arabic simple">
<li><p>N = 1,000 Gaussian blob samples with 10 features divided into 5 clusters (code in <code class="docutils literal notranslate"><span class="pre">blobs.py</span></code>);</p></li>
<li><p>N = 1,000 Gaussian blob samples with 10 features divided into 5 clusters with noise parameter <em>cluster_std</em>
set at 3 (code in <code class="docutils literal notranslate"><span class="pre">blobs.py</span></code>);</p></li>
</ol>
<p>3. N = 14,000 samples from the MNIST handwritten digits dataset loaded from
<a class="reference external" href="https://openml.org/">openml</a> public repository (code in <code class="docutils literal notranslate"><span class="pre">handwrittend_digits.py</span></code>).</p>
<div class="section" id="gaussian-blobs">
<h2>Gaussian blobs<a class="headerlink" href="#gaussian-blobs" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">reval.best_nclust_cv</span> <span class="kn">import</span> <span class="n">FindBestClustCV</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">AgglomerativeClustering</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">zero_one_loss</span><span class="p">,</span> <span class="n">adjusted_mutual_info_score</span>
<span class="kn">from</span> <span class="nn">reval.visualization</span> <span class="kn">import</span> <span class="n">plot_metrics</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">reval.utils</span> <span class="kn">import</span> <span class="n">kuhn_munkres_algorithm</span>
</pre></div>
</div>
<p>Generate sample dataset and visualize blobs (only the first two features).</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">],</span>
            <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow_r&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="_images/blobs1.png" class="align-center" src="_images/blobs1.png" />
<p>We select hierarchical clustering with k-nearest neighbors classifier for number of cluster selection.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">classifier</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">clustering</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">()</span>
</pre></div>
</div>
<p>Then we split the dataset into a training and test sets at 30%. We stratify for class labels.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_tr</span><span class="p">,</span> <span class="n">X_ts</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">,</span> <span class="n">y_ts</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                          <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                          <span class="n">test_size</span><span class="o">=</span><span class="mf">0.30</span><span class="p">,</span>
                                          <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
                                          <span class="n">stratify</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>Apply <code class="docutils literal notranslate"><span class="pre">reval</span></code> with 10 repetitions of 2-fold cross-validation,
10 random labeling iterations, and number of clusters varying from 2 to 6. We then plot model performance
using the function <code class="docutils literal notranslate"><span class="pre">plot_metrics</span></code> from the <code class="docutils literal notranslate"><span class="pre">reval.visualization</span></code> module.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">findbestclust</span> <span class="o">=</span> <span class="n">FindBestClustCV</span><span class="p">(</span><span class="n">nfold</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                <span class="n">nclust_range</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">)),</span>
                                <span class="n">s</span><span class="o">=</span><span class="n">classifier</span><span class="p">,</span>
                                <span class="n">c</span><span class="o">=</span><span class="n">clustering</span><span class="p">,</span>
                                <span class="n">nrand</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">metrics</span><span class="p">,</span> <span class="n">nbest</span> <span class="o">=</span> <span class="n">findbestclust</span><span class="o">.</span><span class="n">best_nclust</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span> <span class="n">iter_cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">strat_vect</span><span class="o">=</span><span class="n">y_tr</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">findbestclust</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span> <span class="n">X_ts</span><span class="p">,</span> <span class="n">nbest</span><span class="p">)</span>
<span class="n">plot_metrics</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Reval performance&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>We obtain that the best number of clusters returned by the model is 5 (see performance plot).</p>
<img alt="_images/performanceblobs1.png" class="align-center" src="_images/performanceblobs1.png" />
<p>Normalized stability in validation is 0.0 (i.e., perfect prediction) and test set accuracy is equal to 1.0.</p>
<p>We are now interested in comparing the clustering labels from the test set with the true labels.
Hence, we first apply Kuhn-Munkres algorithm to permute the labels returned by the model. This
because they may not be ordered as the true labels and lead to an unreliable classification error.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">perm_lab</span> <span class="o">=</span> <span class="n">kuhn_munkres_algorithm</span><span class="p">(</span><span class="n">y_ts</span><span class="p">,</span> <span class="n">out</span><span class="o">.</span><span class="n">test_cllab</span><span class="p">)</span>
</pre></div>
</div>
<p>Then we compute the classification accuracy and the
<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_mutual_info_score.html#sklearn.metrics.adjusted_mutual_info_score">adjusted mutual information score (AMI)</a>
to compare two partitions (this score is independent of label permutations and is equal to 1.0 when two partitions
are identical:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test set external ACC: &quot;</span>
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="mi">1</span> <span class="o">-</span> <span class="n">zero_one_loss</span><span class="p">(</span><span class="n">y_ts</span><span class="p">,</span> <span class="n">perm_lab</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;AMI = </span><span class="si">{</span><span class="n">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">y_ts</span><span class="p">,</span> <span class="n">out</span><span class="o">.</span><span class="n">test_cllab</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>We obtain 100% accuracy and AMI equal to 1.0, see the following scatterplot for visualization of predicted labels.</p>
<img alt="_images/predlabblobs1.png" class="align-center" src="_images/predlabblobs1.png" />
</div>
<div class="section" id="gaussian-blobs-with-noise">
<h2>Gaussian blobs with noise<a class="headerlink" href="#gaussian-blobs-with-noise" title="Permalink to this headline">¶</a></h2>
<p>Let us now consider a synthetic dataset of 1,000 samples and 10 features with added noise. We set the number of
clusters to 5, as previously. In the following, we will observe how the number of clusters returned by <code class="docutils literal notranslate"><span class="pre">reval</span></code>
method is highly influenced by noise. We will show the importance of data pre-processing steps
(e.g., PCA, UMAP for clustering) when applying this method.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_noisy</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data_noisy</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">],</span>
            <span class="n">data_noisy</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">data_noisy</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow_r&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="_images/blobsnoisy.png" class="align-center" src="_images/blobsnoisy.png" />
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">Xnoise_tr</span><span class="p">,</span> <span class="n">Xnoise_ts</span><span class="p">,</span> <span class="n">ynoise_tr</span><span class="p">,</span> <span class="n">ynoise_ts</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data_noisy</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                                              <span class="n">data_noisy</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                                              <span class="n">test_size</span><span class="o">=</span><span class="mf">0.30</span><span class="p">,</span>
                                                              <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
                                                              <span class="n">stratify</span><span class="o">=</span><span class="n">data_noisy</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">metrics_noise</span><span class="p">,</span> <span class="n">nbest_noise</span> <span class="o">=</span> <span class="n">findbestclust</span><span class="o">.</span><span class="n">best_nclust</span><span class="p">(</span><span class="n">Xnoise_tr</span><span class="p">,</span> <span class="n">iter_cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">strat_vect</span><span class="o">=</span><span class="n">ynoise_tr</span><span class="p">)</span>
<span class="n">out_noise</span> <span class="o">=</span> <span class="n">findbestclust</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">Xnoise_tr</span><span class="p">,</span> <span class="n">Xnoise_ts</span><span class="p">,</span> <span class="n">nbest_noise</span><span class="p">)</span>

<span class="n">plot_metrics</span><span class="p">(</span><span class="n">metrics_noise</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Reval performance&quot;</span><span class="p">)</span>

<span class="n">perm_lab_noise</span> <span class="o">=</span> <span class="n">kuhn_munkres_algorithm</span><span class="p">(</span><span class="n">ynoise_ts</span><span class="p">,</span> <span class="n">out_noise</span><span class="o">.</span><span class="n">test_cllab</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Xnoise_ts</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Xnoise_ts</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">perm_lab_noise</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow_r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Clustering labels for test set&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>We observe that the best number of clusters selected is equal to 2, which does not reflect the true label
distributions of the synthetic dataset, although the misclassification performance during training is equal to 0
(see performance plot and scatterplot with predicted labels for the test set).</p>
<img alt="_images/performancenoisy.png" class="align-center" src="_images/performancenoisy.png" />
<img alt="_images/predlabnoisy.png" class="align-center" src="_images/predlabnoisy.png" />
<p>AMI score and accuracy value suggest that the model generalizes poorly on test set.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">AMI</span> <span class="o">=</span> <span class="mf">0.59</span><span class="p">,</span> <span class="n">ACC</span> <span class="o">=</span> <span class="mf">0.4</span>
</pre></div>
</div>
<p>Uniform Manifold Approximation and Projection for Dimensionality Reduction (UMAP; McInnes et al., 2018) is a
topology-based dimensionality reduction tool that can be used to pre-process data for clustering
(see <a class="reference external" href="https://umap-learn.readthedocs.io/en/latest/clustering.html">here</a>). Applied to our noisy dataset with
suggested parameters, we obtain that clusters are correctly identified visually as dense and separated blobs,
that <code class="docutils literal notranslate"><span class="pre">reval</span></code> now easily detects.</p>
<p>McInnes, L, Healy, J, <em>UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction</em>,
ArXiv e-prints 1802.03426, 2018.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">umap</span> <span class="kn">import</span> <span class="n">UMAP</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">UMAP</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">min_dist</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>

<span class="n">Xtr_umap</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">Xnoise_tr</span><span class="p">)</span>
<span class="n">Xts_umap</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xnoise_ts</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Xtr_umap</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Xtr_umap</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">ynoise_tr</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow_r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;UMAP-transformed training set with true labels&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Xts_umap</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Xts_umap</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">ynoise_ts</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow_r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;UMAP-transformed test set with true labels&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Hereafter, we display UMAP pre-processed training and test sets. We fit the UMAP dimensionality reduction technique on
the training set and then applied it to the test set to avoid inflation of performance scores on the test set.</p>
<img alt="_images/trainumap.png" src="_images/trainumap.png" />
<img alt="_images/testumap.png" src="_images/testumap.png" />
<p>Now we apply <code class="docutils literal notranslate"><span class="pre">reval</span></code> method to the transformed dataset.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">metrics</span><span class="p">,</span> <span class="n">nbest</span> <span class="o">=</span> <span class="n">findbestclust</span><span class="o">.</span><span class="n">best_nclust</span><span class="p">(</span><span class="n">Xtr_umap</span><span class="p">,</span> <span class="n">iter_cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">strat_vect</span><span class="o">=</span><span class="n">ynoise_tr</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">findbestclust</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">Xtr_umap</span><span class="p">,</span> <span class="n">Xts_umap</span><span class="p">,</span> <span class="n">nbest</span><span class="p">)</span>

<span class="n">plot_metrics</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Reval performance of UMAP-transformed dataset&#39;</span><span class="p">)</span>

<span class="n">perm_noise</span> <span class="o">=</span> <span class="n">kuhn_munkres_algorithm</span><span class="p">(</span><span class="n">ynoise_ts</span><span class="p">,</span> <span class="n">out</span><span class="o">.</span><span class="n">test_cllab</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best number of clusters: </span><span class="si">{</span><span class="n">nbest</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test set external ACC: &quot;</span>
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="mi">1</span> <span class="o">-</span> <span class="n">zero_one_loss</span><span class="p">(</span><span class="n">ynoise_ts</span><span class="p">,</span> <span class="n">perm_noise</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;AMI = </span><span class="si">{</span><span class="n">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">ynoise_ts</span><span class="p">,</span> <span class="n">out</span><span class="o">.</span><span class="n">test_cllab</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Validation set normalized stability (misclassification): </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">][</span><span class="n">nbest</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Result accuracy (on test set): &quot;</span>
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">out</span><span class="o">.</span><span class="n">test_acc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Xts_umap</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Xts_umap</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">perm_noise</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow_r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Predicted labels for UMAP-preprocessed test set&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>We obtain that 5 clusters are identified (see performance plot) with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ACC</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">;</span> <span class="n">Normalized</span> <span class="n">stability</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
</pre></div>
</div>
<p>Comparing clustering solution (see scatterplot below) with true labels we obtain:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">AMI</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">;</span> <span class="n">ACC</span><span class="p">:</span> <span class="mf">1.0</span>
</pre></div>
</div>
<img alt="_images/performanceumap.png" class="align-center" src="_images/performanceumap.png" />
<img alt="_images/predlabumap.png" class="align-center" src="_images/predlabumap.png" />
</div>
<div class="section" id="mnist-dataset">
<h2>MNIST dataset<a class="headerlink" href="#mnist-dataset" title="Permalink to this headline">¶</a></h2>
<p><strong>Remark: This example enables multiprocessing to speed up computations. ``n_jobs`` parameter in
:class:`FindBestClustCV` set to 7.</strong></p>
<p>From <code class="docutils literal notranslate"><span class="pre">sklearn.datasets</span></code> we can import <code class="docutils literal notranslate"><span class="pre">fetch_openml</span></code> to load MNIST dataset. This dataset includes 70,000
28X28 images of 10 hand-written digits from 0 to 9. To speed up computations we select 14,000 samples that are
divided into training and test sets at 50%. Then, we pre-processed these images with UMAP to reduce the
number of features (from 784 to 10), see scatterplots below.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_openml</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">reval.best_nclust_cv</span> <span class="kn">import</span> <span class="n">FindBestClustCV</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">AgglomerativeClustering</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">zero_one_loss</span><span class="p">,</span> <span class="n">adjusted_mutual_info_score</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">umap</span> <span class="kn">import</span> <span class="n">UMAP</span>
<span class="kn">from</span> <span class="nn">reval.visualization</span> <span class="kn">import</span> <span class="n">plot_metrics</span>
<span class="kn">from</span> <span class="nn">reval.utils</span> <span class="kn">import</span> <span class="n">kuhn_munkres_algorithm</span>

<span class="c1"># MNIST dataset with 10 classes</span>
<span class="n">mnist</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="s1">&#39;mnist_784&#39;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">UMAP</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">min_dist</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Stratified subsets of 7000 elements for both training and test set</span>
<span class="n">mnist_tr</span><span class="p">,</span> <span class="n">mnist_ts</span><span class="p">,</span> <span class="n">label_tr</span><span class="p">,</span> <span class="n">label_ts</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">mnist</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span>
                                                          <span class="n">train_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                                                          <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                                                          <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
                                                          <span class="n">stratify</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>

<span class="c1"># Dimensionality reduction with UMAP as pre-processing step</span>
<span class="n">mnist_tr</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">mnist_tr</span><span class="p">)</span>
<span class="n">mnist_ts</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">mnist_ts</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">mnist_tr</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
            <span class="n">mnist_tr</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">label_tr</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span>
            <span class="n">s</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
            <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow_r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;UMAP-transformed training subsample of MNIST dataset (N=7,000)&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">mnist_ts</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">mnist_ts</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">label_ts</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span> <span class="n">s</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow_r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;UMAP-transformed test subsample of MNIST dataset (N=7,000)&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="_images/trainmnist.png" class="align-center" src="_images/trainmnist.png" />
<img alt="_images/testmnist.png" class="align-center" src="_images/testmnist.png" />
<p>We now apply <code class="docutils literal notranslate"><span class="pre">reval</span></code> with 10 repetitions of  2-fold cross-validation, number of clusters ranging from 2 to 11 and random
labeling iterated 10 times. We again select hierarchical clustering with k-nearest neighbors classifier for
number of cluster selection.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="n">classifier</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">clustering</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">()</span>

<span class="n">findbestclust</span> <span class="o">=</span> <span class="n">FindBestClustCV</span><span class="p">(</span><span class="n">nfold</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">nclust_range</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">12</span><span class="p">)),</span>
                                <span class="n">s</span><span class="o">=</span><span class="n">classifier</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">clustering</span><span class="p">,</span> <span class="n">nrand</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>

<span class="n">metrics</span><span class="p">,</span> <span class="n">nbest</span> <span class="o">=</span> <span class="n">findbestclust</span><span class="o">.</span><span class="n">best_nclust</span><span class="p">(</span><span class="n">mnist_tr</span><span class="p">,</span> <span class="n">iter_cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">strat_vect</span><span class="o">=</span><span class="n">label_tr</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">findbestclust</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">mnist_tr</span><span class="p">,</span> <span class="n">mnist_ts</span><span class="p">,</span> <span class="n">nbest</span><span class="p">)</span>

<span class="n">plot_metrics</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Relative clustering validation performance on MNIST dataset&quot;</span><span class="p">)</span>

<span class="n">perm_lab</span> <span class="o">=</span> <span class="n">kuhn_munkres_algorithm</span><span class="p">(</span><span class="n">label_ts</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span> <span class="n">out</span><span class="o">.</span><span class="n">test_cllab</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">mnist_ts</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">mnist_ts</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
            <span class="n">c</span><span class="o">=</span><span class="n">perm_lab</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow_r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Predicted labels for MNIST test set&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best number of clusters: </span><span class="si">{</span><span class="n">nbest</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test set external ACC: &quot;</span>
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="mi">1</span> <span class="o">-</span> <span class="n">zero_one_loss</span><span class="p">(</span><span class="n">label_ts</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span> <span class="n">perm_lab</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;AMI = </span><span class="si">{</span><span class="n">adjusted_mutual_info_score</span><span class="p">(</span><span class="n">label_ts</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span> <span class="n">perm_lab</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Validation set normalized stability (misclassification): </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">][</span><span class="n">nbest</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Result accuracy (on test set): &quot;</span>
      <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">out</span><span class="o">.</span><span class="n">test_acc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>We obtain that the algorithm returns 6 as the best number of clusters (see performance plot). Comparing true and
predicted labels we obtain a good AMI score, but a low accuracy score:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">AMI</span> <span class="o">=</span> <span class="mf">0.70</span><span class="p">;</span> <span class="n">ACC</span> <span class="o">=</span> <span class="mf">0.58</span>
</pre></div>
</div>
<p>Whereas performance metrics during validation (normalized stability: mean 95% CI) and on test set (ACC)
are low and high, respectively.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Normalized</span> <span class="n">stability</span><span class="p">:</span> <span class="mf">0.002</span> <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.003</span><span class="p">);</span> <span class="n">ACC</span> <span class="o">=</span> <span class="mf">0.99</span>
</pre></div>
</div>
<img alt="_images/performancemnist.png" class="align-center" src="_images/performancemnist.png" />
<p>We observe that the classes correctly identified are those that, after UMAP reduction, show good cohesion and separation,
which is why the model performance is good.
On the contrary, clusters that are closer together receive the same labels (see scatterplot below) and are misclassified.
This lowers the external ACC score although returning a high AMI score, which is based on cluster overlaps.</p>
<img alt="_images/predlabmnist.png" class="align-center" src="_images/predlabmnist.png" />
<p>In these situations attention should be put in:</p>
<ol class="arabic simple">
<li><p>Choosing the right clustering algorithm;</p></li>
<li><p>Pre-processing steps;</p></li>
<li><p>Whether <code class="docutils literal notranslate"><span class="pre">reval</span></code> is the right method to use with the data at hand (e.g., very noisy dataset with unknown labels).</p></li>
</ol>
</div>
<div class="section" id="more-examples">
<h2>More examples<a class="headerlink" href="#more-examples" title="Permalink to this headline">¶</a></h2>
<p>Check out more examples including (1) repeated cross validation
with HDBSCAN algorithm for the complete MNIST handwritten digits dataset,
and (2) <code class="docutils literal notranslate"><span class="pre">reval</span></code> for classifier/clustering selection
<a class="reference external" href="https://arxiv.org/abs/2009.01077">here</a>. Code can be found in the cloned folder
in <em>reval_clustering/working_examples</em>.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="datadimension.html" class="btn btn-neutral float-right" title="Examples of how things can go wrong" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="code_usage.html" class="btn btn-neutral float-left" title="How to use reval" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Isotta Landi

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>