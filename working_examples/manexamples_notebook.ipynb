{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples from manuscript\n",
    "\n",
    "Code to run the examples reported in https://arxiv.org/abs/2009.01077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reval.best_nclust_cv import FindBestClustCV\n",
    "from reval.internal_baselines import select_best, evaluate_best\n",
    "from reval.visualization import plot_metrics\n",
    "from reval.utils import kuhn_munkres_algorithm, compute_metrics\n",
    "from reval.param_selection import ParamSelection, SCParamSelection\n",
    "from datasets.manuscript_builddatasets import build_ucidatasets\n",
    "\n",
    "from sklearn.datasets import make_blobs, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans, SpectralClustering\n",
    "from sklearn.metrics import zero_one_loss, adjusted_mutual_info_score, silhouette_score, davies_bouldin_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import hdbscan\n",
    "from umap import UMAP\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modify this variable for parallelization\n",
    "N_JOBS=7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three example functions that can also be run from shell (see manuscript_examples.py file). \n",
    "\n",
    "> Example 1: blobs dataset;\n",
    "\n",
    "> Example 2: real-world dataset MNIST;\n",
    "\n",
    "> Example 3: best clussifier-clustering combinations for 18 datasets from UCI Machine Learning Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: blobs dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 1: Isotropic Gaussian blobs\n",
    "# Generate dataset\n",
    "data = make_blobs(1000, 2, centers=5, \n",
    "                  center_box=(-20, 20),\n",
    "                  random_state=42)\n",
    "\n",
    "# Visualize dataset\n",
    "plt.figure(figsize=(6, 4))\n",
    "for i in range(5):\n",
    "    plt.scatter(data[0][data[1]==i][:, 0],\n",
    "                data[0][data[1]==i][:, 1],\n",
    "                label=i, cmap='tab20')\n",
    "plt.title(\"Blobs dataset\")\n",
    "# plt.savefig('./blobs.png', format='png')\n",
    "plt.show()\n",
    "\n",
    "# Create training and test sets\n",
    "X_tr, X_ts, y_tr, y_ts = train_test_split(data[0],\n",
    "                                          data[1],\n",
    "                                          test_size=0.30,\n",
    "                                          random_state=42,\n",
    "                                          stratify=data[1])\n",
    "\n",
    "# Initialize clustering and classifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=15)\n",
    "clustering = KMeans()\n",
    "\n",
    "# Run relatve validation (repeated CV and testing)\n",
    "findbestclust = FindBestClustCV(nfold=2,\n",
    "                                nclust_range=list(range(2, 7, 1)),\n",
    "                                s=classifier,\n",
    "                                c=clustering,\n",
    "                                nrand=10,\n",
    "                                n_jobs=N_JOBS)\n",
    "metrics, nbest = findbestclust.best_nclust(X_tr, iter_cv=10, strat_vect=y_tr)\n",
    "out = findbestclust.evaluate(X_tr, X_ts, nclust=nbest)\n",
    "\n",
    "# Plot CV metrics\n",
    "plot_metrics(metrics, prob_lines=False)\n",
    "logging.info(f\"Validation stability: {metrics['val'][nbest]}\")\n",
    "perm_lab = kuhn_munkres_algorithm(y_ts, out.test_cllab)\n",
    "\n",
    "logging.info(f\"Best number of clusters: {nbest}\")\n",
    "logging.info(f'AMI (true labels vs predicted labels) for test set = '\n",
    "      f'{adjusted_mutual_info_score(y_ts, out.test_cllab)}')\n",
    "logging.info('\\n\\n')\n",
    "\n",
    "# Compute metrics\n",
    "logging.info(\"Metrics from true label comparisons on test set:\")\n",
    "class_scores = compute_metrics(y_ts, perm_lab, perm=False)\n",
    "for k, val in class_scores.items():\n",
    "    if k in ['ACC', 'MCC']:\n",
    "        logging.info(f\"{k}, {val}\")\n",
    "logging.info(\"\\n\\n\")\n",
    "\n",
    "# Internal measures\n",
    "# SILHOUETTE\n",
    "logging.info(\"Silhouette score based selection\")\n",
    "sil_score_tr, sil_best_tr, sil_label_tr = select_best(X_tr, clustering, silhouette_score,\n",
    "                                                      select='max',\n",
    "                                                      nclust_range=list(range(2, 7, 1)))\n",
    "sil_score_ts, sil_best_ts, sil_label_ts = select_best(X_ts, clustering, silhouette_score,\n",
    "                                                      select='max',\n",
    "                                                      nclust_range=list(range(2, 7, 1)))\n",
    "\n",
    "sil_eval = evaluate_best(X_ts, clustering, silhouette_score, sil_best_tr)\n",
    "\n",
    "logging.info(f\"Best number of clusters (and scores) for tr/ts independent runs: \"\n",
    "             f\"{sil_best_tr}({sil_score_tr})/{sil_best_ts}({sil_score_ts})\")\n",
    "logging.info(f\"Test set evaluation {sil_eval}\")\n",
    "logging.info(f'AMI (true labels vs clustering labels) training = '\n",
    "                 f'{adjusted_mutual_info_score(y_tr, kuhn_munkres_algorithm(y_tr, sil_label_tr))}')\n",
    "logging.info(f'AMI (true labels vs clustering labels) test = '\n",
    "                 f'{adjusted_mutual_info_score(y_ts, kuhn_munkres_algorithm(y_ts, sil_label_ts))}')\n",
    "logging.info('\\n\\n')\n",
    "\n",
    "# DAVIES-BOULDIN\n",
    "logging.info(\"Davies-Bouldin score based selection\")\n",
    "db_score_tr, db_best_tr, db_label_tr = select_best(X_tr, clustering, davies_bouldin_score, \n",
    "                                        select='min', nclust_range=list(range(2, 7, 1)))\n",
    "db_score_ts, db_best_ts, db_label_ts = select_best(X_ts, clustering, davies_bouldin_score, \n",
    "                                        select='min', nclust_range=list(range(2, 7, 1)))\n",
    "\n",
    "db_eval = evaluate_best(X_ts, clustering, davies_bouldin_score, db_best_tr)\n",
    "\n",
    "logging.info(f\"Best number of clusters (and scores) for tr/ts independent runs: \"\n",
    "             f\"{db_best_tr}({db_score_tr})/{db_best_ts}({db_score_ts})\")\n",
    "logging.info(f\"Test set evaluation {db_eval}\")\n",
    "logging.info(f'AMI (true labels vs clustering labels) training = '\n",
    "                 f'{adjusted_mutual_info_score(y_tr, kuhn_munkres_algorithm(y_tr, db_label_tr))}')\n",
    "logging.info(f'AMI (true labels vs clustering labels) test = '\n",
    "                 f'{adjusted_mutual_info_score(y_ts, kuhn_munkres_algorithm(y_ts, db_label_ts))}')\n",
    "logging.info('\\n\\n')\n",
    "\n",
    "# Plot true vs predicted labels for test sets\n",
    "plt.figure(figsize=(6, 4))\n",
    "for i in range(5):\n",
    "    plt.scatter(X_ts[y_ts==i][:, 0], \n",
    "                X_ts[y_ts==i][:, 1],\n",
    "                label=str(i),\n",
    "                cmap='tab20')\n",
    "plt.legend(loc=3)\n",
    "plt.title(\"Test set true labels\")\n",
    "# plt.savefig('./blobs_true.png', format='png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "for i in range(5):\n",
    "    plt.scatter(X_ts[perm_lab==i][:, 0], \n",
    "                X_ts[perm_lab==i][:, 1],\n",
    "                label=str(i),\n",
    "                cmap='tab20')\n",
    "plt.legend(loc=3)\n",
    "plt.title(\"Test set clustering labels\")\n",
    "# plt.savefig('./blobs_clustering.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: MNIST real-world dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: MNIST dataset\n",
    "# Load the dataset\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.target = mnist.target.astype(int)\n",
    "\n",
    "# Create training and test sets\n",
    "X_tr, y_tr = mnist['data'][:60000], mnist.target[:60000]\n",
    "X_ts, y_ts = mnist['data'][60000::], mnist.target[60000::]\n",
    "transform = UMAP(n_components=2,\n",
    "                 random_state=42,\n",
    "                 n_neighbors=30,\n",
    "                 min_dist=0.0)\n",
    "X_tr = transform.fit_transform(X_tr)\n",
    "X_ts = transform.transform(X_ts)\n",
    "\n",
    "#Initialize classifier/clustering algorithms\n",
    "combo = {'s': [KNeighborsClassifier(n_neighbors=30), SVC(), LogisticRegression(), RandomForestClassifier()],\n",
    "         'c': [hdbscan.HDBSCAN(min_samples=10, min_cluster_size=200)]}\n",
    "\n",
    "scsel = SCParamSelection(combo, 2, 10, 7, 10, list(range(2, 13)), y_tr)\n",
    "scsel.fit(X_tr, 10)\n",
    "\n",
    "# s = KNeighborsClassifier(n_neighbors=30)\n",
    "s = RandomForestClassifier()\n",
    "c = hdbscan.HDBSCAN(min_samples=10, min_cluster_size=200)\n",
    "\n",
    "reval = FindBestClustCV(s=s,\n",
    "                        c=c,\n",
    "                        nfold=2,\n",
    "                        nrand=10,\n",
    "                        n_jobs=N_JOBS)\n",
    "\n",
    "metrics, nclustbest, tr_lab = reval.best_nclust(X_tr, iter_cv=10, strat_vect=y_tr)\n",
    "\n",
    "plot_metrics(metrics, save_fig='mnist_performance.png')\n",
    "logging.info(f\"Validation stability: {metrics['val'][nclustbest]}\")\n",
    "\n",
    "out = reval.evaluate(X_tr, X_ts, nclust=nclustbest, tr_lab=tr_lab)\n",
    "perm_lab = kuhn_munkres_algorithm(y_ts, out.test_cllab)\n",
    "\n",
    "logging.info(f\"Best number of clusters during CV: {nclustbest}\")\n",
    "logging.info(f\"Best number of clusters on test set: {len([lab for lab in np.unique(out.test_cllab) if lab >= 0])}\")\n",
    "logging.info(f'AMI train (true labels vs predicted labels) = '\n",
    "             f'{adjusted_mutual_info_score(y_tr, out.train_cllab)}')\n",
    "logging.info('\\n\\n')\n",
    "logging.info(f'AMI (true labels vs predicted labels) = '\n",
    "             f'{adjusted_mutual_info_score(y_ts, out.test_cllab)}')\n",
    "logging.info('\\n\\n')\n",
    "\n",
    "logging.info(\"Metrics from true label comparisons on test set:\")\n",
    "class_scores = compute_metrics(y_ts, perm_lab)\n",
    "for k, val in class_scores.items():\n",
    "    logging.info(f'{k}, {val}')\n",
    "logging.info('\\n\\n')\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter = ax.scatter(X_tr[:, 0],\n",
    "                     X_tr[:, 1],\n",
    "                     c=y_tr, \n",
    "                     cmap='tab20',\n",
    "                     s=0.1)\n",
    "legend = ax.legend(*scatter.legend_elements())\n",
    "ax.add_artist(legend)\n",
    "plt.title(\"\")\n",
    "# plt.savefig('./mnist_train.png')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter = ax.scatter(X_tr[:, 0],\n",
    "                     X_tr[:, 1],\n",
    "                     c=kuhn_munkres_algorithm(y_tr, tr_lab), \n",
    "                     cmap='tab20',\n",
    "                     s=0.1)\n",
    "legend = ax.legend(*scatter.legend_elements())\n",
    "ax.add_artist(legend)\n",
    "plt.title(\"\")\n",
    "# plt.savefig('./mnist_trainreval.png')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter = ax.scatter(X_ts[:, 0],\n",
    "                    X_ts[:, 1],\n",
    "                    c=y_ts, cmap='tab20',\n",
    "                    s=0.1)\n",
    "legend = ax.legend(*scatter.legend_elements())\n",
    "ax.add_artist(legend)\n",
    "plt.title(\"\")\n",
    "# plt.savefig('./mnist_test.png')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter = ax.scatter(X_ts[:, 0],\n",
    "                X_ts[:, 1],\n",
    "                s=0.1,\n",
    "                c=perm_lab, cmap='tab20')\n",
    "legend = ax.legend(*scatter.legend_elements())\n",
    "ax.add_artist(legend)\n",
    "plt.title(\"\")\n",
    "# plt.savefig('./mnist_testreval.png')\n",
    "plt.show()\n",
    "\n",
    "# Internal measures\n",
    "# SILHOUETTE\n",
    "logging.info(\"Silhouette score based selection\")\n",
    "sil_score_tr, sil_best_tr, sil_label_tr = select_best(X_tr, c, silhouette_score, select='max')\n",
    "sil_score_ts, sil_best_ts, sil_label_ts = select_best(X_ts, c, silhouette_score, select='max')\n",
    "logging.info(f\"Best number of clusters (and scores) for tr/ts independent runs: {sil_best_tr}({sil_score_tr})/{sil_best_ts}({sil_score_ts})\")\n",
    "logging.info(f'AMI (true labels vs clustering labels) training = '\n",
    "                 f'{adjusted_mutual_info_score(y_tr, kuhn_munkres_algorithm(y_tr, sil_label_tr))}')\n",
    "logging.info(f'AMI (true labels vs clustering labels) test = '\n",
    "                 f'{adjusted_mutual_info_score(y_ts, kuhn_munkres_algorithm(y_ts, sil_label_ts))}')\n",
    "logging.info('\\n\\n')\n",
    "\n",
    "# DAVIES-BOULDIN\n",
    "logging.info(\"Davies-Bouldin score based selection\")\n",
    "db_score_tr, db_best_tr, db_label_tr = select_best(X_tr, c, davies_bouldin_score, \n",
    "                                        select='min')\n",
    "db_score_ts, db_best_ts, db_label_ts = select_best(X_ts, c, davies_bouldin_score, \n",
    "                                        select='min')\n",
    "\n",
    "logging.info(f\"Best number of clusters (and scores) for tr/ts independent runs: {db_best_tr}({db_score_tr})/{db_best_ts}({db_score_ts})\")\n",
    "logging.info(f'AMI (true labels vs clustering labels) training = '\n",
    "                 f'{adjusted_mutual_info_score(y_tr, kuhn_munkres_algorithm(y_tr, db_label_tr))}')\n",
    "logging.info(f'AMI (true labels vs clustering labels) test = '\n",
    "                 f'{adjusted_mutual_info_score(y_ts, kuhn_munkres_algorithm(y_ts, db_label_ts))}')\n",
    "logging.info('\\n\\n')\n",
    "\n",
    "#Visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter = ax.scatter(X_tr[:, 0],\n",
    "                     X_tr[:, 1],\n",
    "                     c=sil_label_tr, \n",
    "                     cmap='tab20',\n",
    "                     s=0.1)\n",
    "legend = ax.legend(*scatter.legend_elements())\n",
    "ax.add_artist(legend)\n",
    "plt.title(\"\")\n",
    "# plt.savefig('./mnist_trainsilh.png')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter = ax.scatter(X_ts[:, 0],\n",
    "                     X_ts[:, 1],\n",
    "                     c=sil_label_ts, \n",
    "                     cmap='tab20',\n",
    "                     s=0.1)\n",
    "legend = ax.legend(*scatter.legend_elements())\n",
    "ax.add_artist(legend)\n",
    "legend = ax.legend(*scatter.legend_elements())\n",
    "ax.add_artist(legend)\n",
    "plt.title(\"\")\n",
    "# plt.savefig('./mnist_testsilh.png')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter = ax.scatter(X_tr[:, 0],\n",
    "                     X_tr[:, 1],\n",
    "                     c=db_label_tr, \n",
    "                     cmap='tab20',\n",
    "                     s=0.1)\n",
    "legend = ax.legend(*scatter.legend_elements())\n",
    "ax.add_artist(legend)\n",
    "plt.title(\"\")\n",
    "# plt.savefig('./mnist_traindb.png')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter = ax.scatter(X_ts[:, 0],\n",
    "                     X_ts[:, 1],\n",
    "                     s=0.1,\n",
    "                     c=db_label_ts, \n",
    "                     cmap='tab20')\n",
    "legend = ax.legend(*scatter.legend_elements())\n",
    "ax.add_artist(legend)\n",
    "plt.title(\"\")\n",
    "# plt.savefig('./mnist_testdb.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: best classifier/clustering combination search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: best clussifier/clustering for UCI dataset\n",
    "# Import benchmark datasets\n",
    "uci_data = build_ucidatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers\n",
    "s = [LogisticRegression(solver='liblinear',\n",
    "                        random_state=42),\n",
    "     RandomForestClassifier(n_estimators=100,\n",
    "                            random_state=42),\n",
    "     KNeighborsClassifier(n_neighbors=1,\n",
    "                           metric='euclidean'),\n",
    "     SVC(C=1,\n",
    "         random_state=42)]\n",
    "\n",
    "# Clustering\n",
    "c = [AgglomerativeClustering(), \n",
    "     KMeans(random_state=42),\n",
    "     hdbscan.HDBSCAN()]\n",
    "\n",
    "scparam = {'s': s,\n",
    "           'c': c}\n",
    "\n",
    "transform = UMAP(n_neighbors=30, min_dist=0.0, random_state=42)\n",
    "scale = StandardScaler()\n",
    "\n",
    "# Run parameter selection algorithm\n",
    "best_results = {}\n",
    "for data, name in zip(uci_data, uci_data._fields):\n",
    "    if name == 'hwdigits':\n",
    "        scparam['s'][-1].gamma = (1 / data['data'].shape[0])\n",
    "        nclass = len(np.unique(data['target']))\n",
    "        logging.info(f\"Processing dataset {name}\")\n",
    "        logging.info(f\"True number of classes: {nclass}\\n\")\n",
    "        X_tr, X_ts, y_tr, y_ts = train_test_split(data['data'],\n",
    "                                                  data['target'],\n",
    "                                                  test_size=0.40,\n",
    "                                                  random_state=42,\n",
    "                                                  stratify=data['target'])\n",
    "        # Change here for different preprocessing\n",
    "        X_tr = transform.fit_transform(X_tr)\n",
    "        X_ts = transform.transform(X_ts)\n",
    "        scparam_select = SCParamSelection(sc_params=scparam,\n",
    "                                          cv=2,\n",
    "                                          nrand=10,\n",
    "                                          clust_range=list(range(2, nclass+3, 1)),\n",
    "                                          n_jobs=N_JOBS,\n",
    "                                          iter_cv=10,\n",
    "                                          strat=y_tr)\n",
    "        scparam_select.fit(X_tr, nclass=nclass)\n",
    "        best_results[name] = scparam_select.best_param_\n",
    "        # Uncomment to save the results\n",
    "    #     pkl.dump(best_results, open('./best_resultUCI_scaledumap.pkl', 'wb'))\n",
    "        logging.info('*' * 100)\n",
    "        logging.info('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that fits the best models to the UCI datasets and reports the results\n",
    "def test_ucibest(X_tr, X_ts, y_tr, y_ts, best_sol, \n",
    "                 n_jobs=1, preprocess=None, tr_lab=None):\n",
    "    reval = FindBestClustCV(s=best_sol['s'],\n",
    "                            c=best_sol['c'],\n",
    "                            nfold=2,\n",
    "                            nrand=10,\n",
    "                            n_jobs=n_jobs)\n",
    "\n",
    "    transform = UMAP(n_neighbors=30, min_dist=0.0, random_state=42)\n",
    "    scale = StandardScaler()\n",
    "\n",
    "    if preprocess == 'scaled':\n",
    "        X_tr = scale.fit_transform(X_tr)\n",
    "        X_ts = scale.transform(X_ts)\n",
    "    elif preprocess == 'umap':\n",
    "        X_tr = transform.fit_transform(X_tr)\n",
    "        X_ts = transform.transform(X_ts)\n",
    "    elif preprocess == 'scaled+umap':\n",
    "        X_tr = transform.fit_transform(scale.fit_transform(X_tr))\n",
    "        X_ts = transform.transform(scale.transform(X_ts))\n",
    "\n",
    "    if isinstance(best_sol['c'], hdbscan.HDBSCAN):\n",
    "        _, _, tr_lab = reval.best_nclust(X_tr, iter_cv=1, strat_vect=y_tr)\n",
    "        \n",
    "    out = reval.evaluate(X_tr, X_ts, nclust=best_sol['nclust'], tr_lab=tr_lab)\n",
    "    perm_lab = kuhn_munkres_algorithm(y_ts, out.test_cllab)\n",
    "\n",
    "    logging.info(f'Testing solution {best_sol}.')\n",
    "    logging.info(f\"Best number of clusters during CV: {best_sol['nclust']}\")\n",
    "    logging.info(f\"Best number of clusters on test set: {len([lab for lab in np.unique(out.test_cllab) if lab >= 0])}\")\n",
    "    logging.info(f\"Test set accuracy: {out.test_acc}\")\n",
    "    logging.info(f'AMI (true labels vs predicted labels) = '\n",
    "                 f'{adjusted_mutual_info_score(y_ts, out.test_cllab)}')\n",
    "    logging.info('\\n\\n')\n",
    "    \n",
    "    logging.info(\"Metrics from true label comparisons on test set:\")\n",
    "    class_scores = compute_metrics(y_ts, perm_lab)\n",
    "    logging.info('\\n\\n')\n",
    "    \n",
    "    for k, val in class_scores.items():\n",
    "        logging.info(f\"{k}, {val}\")\n",
    "\n",
    "    # Internal measures\n",
    "    # SILHOUETTE\n",
    "    logging.info(\"Silhouette score based selection\")\n",
    "    sil_score_tr, sil_best_tr, sil_label_tr = select_best(X_tr, best_sol['c'], silhouette_score, select='max')\n",
    "    sil_score_ts, sil_best_ts, sil_label_ts = select_best(X_ts, best_sol['c'], silhouette_score, select='max')\n",
    "    logging.info(f\"Best number of clusters (and scores) for tr/ts independent \"\n",
    "                 f\"runs: {sil_best_tr}({sil_score_tr})/{sil_best_ts}({sil_score_ts})\")\n",
    "    logging.info(f'AMI (true labels vs clustering labels) training = '\n",
    "                 f'{adjusted_mutual_info_score(y_tr, kuhn_munkres_algorithm(y_tr, sil_label_tr))}')\n",
    "    logging.info(f'AMI (true labels vs clustering labels) test = '\n",
    "                 f'{adjusted_mutual_info_score(y_ts, kuhn_munkres_algorithm(y_ts, sil_label_ts))}')\n",
    "    logging.info(f\"Silhouette metrics: {compute_metrics(y_ts, kuhn_munkres_algorithm(y_ts, sil_label_ts))}\")\n",
    "    logging.info('\\n\\\\n')\n",
    "    \n",
    "    # DAVIES-BOULDIN\n",
    "    logging.info(\"Davies-Bouldin score based selection\")\n",
    "    db_score_tr, db_best_tr, db_label_tr = select_best(X_tr, best_sol['c'], davies_bouldin_score,\n",
    "                                                       select='min')\n",
    "    db_score_ts, db_best_ts, db_label_ts = select_best(X_ts, best_sol['c'], davies_bouldin_score,\n",
    "                                                       select='min')\n",
    "\n",
    "    logging.info(f\"Best number of clusters (and scores) for tr/ts independent \"\n",
    "                 f\"runs: {db_best_tr}({db_score_tr})/{db_best_ts}({db_score_ts})\")\n",
    "    logging.info(f'AMI (true labels vs clustering labels) training = '\n",
    "                 f'{adjusted_mutual_info_score(y_tr, kuhn_munkres_algorithm(y_tr, db_label_tr))}')\n",
    "    logging.info(f'AMI (true labels vs clustering labels) test = '\n",
    "                 f'{adjusted_mutual_info_score(y_ts, kuhn_munkres_algorithm(y_ts, db_label_ts))}')\n",
    "    logging.info(f\"Davies-Bouldin metrics: {compute_metrics(y_ts, kuhn_munkres_algorithm(y_ts, db_label_ts))}\")\n",
    "    logging.info('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best solutions with raw data\n",
    "Dataset whose best solutions don't require preprocessing are: biodeg, breastwi, ionosphere, seeds, and forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read pkl objects with best solutions\n",
    "best_raw = pkl.load(open('../best_resultUCI_raw.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `biodeg` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biodeg_best = {'s': best_raw['biodeg'][0][0],\n",
    "               'c': best_raw['biodeg'][0][1],\n",
    "               'nclust': best_raw['biodeg'][0][2]}\n",
    "biodeg_tr, biodeg_ts, biodeg_y_tr, biodeg_y_ts = train_test_split(uci_data.biodeg['data'],\n",
    "                                                                  uci_data.biodeg['target'],\n",
    "                                                                  test_size=0.40,\n",
    "                                                                  random_state=42,\n",
    "                                                                  stratify=uci_data.biodeg['target'])\n",
    "test_ucibest(biodeg_tr, biodeg_ts, biodeg_y_tr, biodeg_y_ts, biodeg_best, n_jobs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `breastwi` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_best = {'s': best_raw['breastwi'][0][0],\n",
    "               'c': best_raw['breastwi'][0][1],\n",
    "               'nclust': best_raw['breastwi'][0][2]}\n",
    "breast_tr, breast_ts, breast_y_tr, breast_y_ts = train_test_split(uci_data.breastwi['data'],\n",
    "                                                                  uci_data.breastwi['target'],\n",
    "                                                                  test_size=0.40,\n",
    "                                                                  random_state=42,\n",
    "                                                                  stratify=uci_data.breastwi['target'])\n",
    "test_ucibest(breast_tr, breast_ts, breast_y_tr, breast_y_ts, breast_best, n_jobs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ionosphere` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ionosphere_best = {'s': best_raw['ionosphere'][0][0],\n",
    "               'c': best_raw['ionosphere'][0][1],\n",
    "               'nclust': best_raw['ionosphere'][0][2]}\n",
    "ionosphere_tr, ionosphere_ts, ionosphere_y_tr, ionosphere_y_ts = train_test_split(uci_data.ionosphere['data'],\n",
    "                                                                  uci_data.ionosphere['target'],\n",
    "                                                                  test_size=0.40,\n",
    "                                                                  random_state=42,\n",
    "                                                                  stratify=uci_data.ionosphere['target'])\n",
    "test_ucibest(ionosphere_tr, ionosphere_ts, ionosphere_y_tr, ionosphere_y_ts, ionosphere_best, n_jobs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `seeds` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_best = {'s': best_raw['seeds'][0][0],\n",
    "               'c': best_raw['seeds'][0][1],\n",
    "               'nclust': best_raw['seeds'][0][2]}\n",
    "seeds_tr, seeds_ts, seeds_y_tr, seeds_y_ts = train_test_split(uci_data.seeds['data'],\n",
    "                                                                  uci_data.seeds['target'],\n",
    "                                                                  test_size=0.40,\n",
    "                                                                  random_state=42,\n",
    "                                                                  stratify=uci_data.seeds['target'])\n",
    "test_ucibest(seeds_tr, seeds_ts, seeds_y_tr, seeds_y_ts, seeds_best, n_jobs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `forest` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_best = {'s': best_raw['forest'][0][0],\n",
    "               'c': best_raw['forest'][0][1],\n",
    "               'nclust': best_raw['forest'][0][2]}\n",
    "forest_tr, forest_ts, forest_y_tr, forest_y_ts = train_test_split(uci_data.forest['data'],\n",
    "                                                                  uci_data.forest['target'],\n",
    "                                                                  test_size=0.40,\n",
    "                                                                  random_state=42,\n",
    "                                                                  stratify=uci_data.forest['target'])\n",
    "test_ucibest(forest_tr, forest_ts, forest_y_tr, forest_y_ts, forest_best, n_jobs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best solutions with UMAP preprocessed data\n",
    "Datasets that require uniform manifold approximation and projection (UMAP) preprocessing are: hwdigits, iris, liver, movement, wholesale, ecoli, transfusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read pkl objects with best solutions\n",
    "best_umap = pkl.load(open('../best_resultUCI_umap.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `hwdigits` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwdigits_best = {'s': best_umap['hwdigits'][0][0],\n",
    "                 'c': best_umap['hwdigits'][0][1],\n",
    "                 'nclust': best_umap['hwdigits'][0][2]}\n",
    "\n",
    "hwdigits_tr, hwdigits_ts, hwdigits_y_tr, hwdigits_y_ts = train_test_split(uci_data.hwdigits['data'],\n",
    "                                                                          uci_data.hwdigits['target'],\n",
    "                                                                          test_size=0.40,\n",
    "                                                                          random_state=42,\n",
    "                                                                          stratify=uci_data.hwdigits['target'])\n",
    "\n",
    "test_ucibest(hwdigits_tr, hwdigits_ts, hwdigits_y_tr, hwdigits_y_ts, hwdigits_best, preprocess='umap', n_jobs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `iris` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_best = {'s': best_umap['iris'][0][0],\n",
    "               'c': best_umap['iris'][0][1],\n",
    "               'nclust': best_umap['iris'][0][2]}\n",
    "iris_tr, iris_ts, iris_y_tr, iris_y_ts = train_test_split(uci_data.iris['data'],\n",
    "                                                                  uci_data.iris['target'],\n",
    "                                                                  test_size=0.40,\n",
    "                                                                  random_state=42,\n",
    "                                                                  stratify=uci_data.iris['target'])\n",
    "\n",
    "test_ucibest(iris_tr, iris_ts, iris_y_tr, iris_y_ts, iris_best, preprocess='umap', n_jobs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `liver` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liver_best = {'s': best_umap['liver'][0][0],\n",
    "               'c': best_umap['liver'][0][1],\n",
    "               'nclust': best_umap['liver'][0][2]}\n",
    "liver_tr, liver_ts, liver_y_tr, liver_y_ts = train_test_split(uci_data.liver['data'],\n",
    "                                                                  uci_data.liver['target'],\n",
    "                                                                  test_size=0.40,\n",
    "                                                                  random_state=42,\n",
    "                                                                  stratify=uci_data.liver['target'])\n",
    "test_ucibest(liver_tr, liver_ts, liver_y_tr, liver_y_ts, liver_best, \n",
    "             preprocess='umap', n_jobs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `movement` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_best = {'s': best_umap['movement'][0][0],\n",
    "               'c': best_umap['movement'][0][1],\n",
    "               'nclust': best_umap['movement'][0][2]}\n",
    "movement_tr, movement_ts, movement_y_tr, movement_y_ts = train_test_split(uci_data.movement['data'],\n",
    "                                                                  uci_data.movement['target'],\n",
    "                                                                  test_size=0.40,\n",
    "                                                                  random_state=42,\n",
    "                                                                  stratify=uci_data.movement['target'])\n",
    "test_ucibest(movement_tr, movement_ts, movement_y_tr, movement_y_ts, movement_best, \n",
    "             preprocess='umap', n_jobs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `wholesale` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wholesale_best = {'s': best_umap['wholesale'][0][0],\n",
    "               'c': best_umap['wholesale'][0][1],\n",
    "               'nclust': best_umap['wholesale'][0][2]}\n",
    "wholesale_tr, wholesale_ts, wholesale_y_tr, wholesale_y_ts = train_test_split(uci_data.wholesale['data'],\n",
    "                                                                  uci_data.wholesale['target'],\n",
    "                                                                  test_size=0.40,\n",
    "                                                                  random_state=42,\n",
    "                                                                  stratify=uci_data.wholesale['target'])\n",
    "test_ucibest(wholesale_tr, wholesale_ts, wholesale_y_tr, wholesale_y_ts, wholesale_best, \n",
    "             preprocess='umap', n_jobs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ecoli` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecoli_best = {'s': best_umap['ecoli'][-2][0],\n",
    "               'c': best_umap['ecoli'][-2][1],\n",
    "               'nclust': best_umap['ecoli'][-2][2]}\n",
    "ecoli_tr, ecoli_ts, ecoli_y_tr, ecoli_y_ts = train_test_split(uci_data.ecoli['data'],\n",
    "                                                                  uci_data.ecoli['target'],\n",
    "                                                                  test_size=0.40,\n",
    "                                                                  random_state=42,\n",
    "                                                                  stratify=uci_data.ecoli['target'])\n",
    "test_ucibest(ecoli_tr, ecoli_ts, ecoli_y_tr, ecoli_y_ts, ecoli_best, \n",
    "             preprocess='umap', n_jobs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `transfusion` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfusion_best = {'s': best_umap['transfusion'][-2][0],\n",
    "               'c': best_umap['transfusion'][-2][1],\n",
    "               'nclust': best_umap['transfusion'][-2][2]}\n",
    "transfusion_tr, transfusion_ts, transfusion_y_tr, transfusion_y_ts = train_test_split(uci_data.transfusion['data'],\n",
    "                                                                  uci_data.transfusion['target'],\n",
    "                                                                  test_size=0.40,\n",
    "                                                                  random_state=42,\n",
    "                                                                  stratify=uci_data.transfusion['target'])\n",
    "test_ucibest(transfusion_tr, transfusion_ts, transfusion_y_tr, transfusion_y_ts, transfusion_best, \n",
    "             preprocess='umap', n_jobs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best solutions with scaled data\n",
    "Datasets: glass, leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read pkl objects with best solutions\n",
    "best_scaled = pkl.load(open('../best_resultUCI_scaled.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `glass` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass_best = {'s': best_scaled['glass'][0][0],\n",
    "               'c': best_scaled['glass'][0][1],\n",
    "               'nclust': best_scaled['glass'][0][2]}\n",
    "glass_tr, glass_ts, glass_y_tr, glass_y_ts = train_test_split(uci_data.glass['data'],\n",
    "                                                                  uci_data.glass['target'],\n",
    "                                                                  test_size=0.40,\n",
    "                                                                  random_state=42,\n",
    "                                                                  stratify=uci_data.glass['target'])\n",
    "test_ucibest(glass_tr, glass_ts, glass_y_tr, glass_y_ts, glass_best, \n",
    "             preprocess='scaled', n_jobs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `leaf` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_best = {'s': best_scaled['leaf'][0][0],\n",
    "               'c': best_scaled['leaf'][0][1],\n",
    "               'nclust': best_scaled['leaf'][0][2]}\n",
    "leaf_tr, leaf_ts, leaf_y_tr, leaf_y_ts = train_test_split(uci_data.leaf['data'],\n",
    "                                                                  uci_data.leaf['target'],\n",
    "                                                                  test_size=0.40,\n",
    "                                                                  random_state=42,\n",
    "                                                                  stratify=uci_data.leaf['target'])\n",
    "test_ucibest(leaf_tr, leaf_ts, leaf_y_tr, leaf_y_ts, leaf_best, \n",
    "             preprocess='scaled', n_jobs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best solutions with scaled+UMAP preprocessed data\n",
    "Datasets: climate, banknote, parkinsons, yeast, urban."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read pkl objects with best solutions\n",
    "best_scaledumap = pkl.load(open('../best_resultUCI_scaledumap.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `climate` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_best = {'s': best_scaledumap['climate'][0][0],\n",
    "               'c': best_scaledumap['climate'][0][1],\n",
    "               'nclust': best_scaledumap['climate'][0][2]}\n",
    "climate_tr, climate_ts, climate_y_tr, climate_y_ts = train_test_split(uci_data.climate['data'],\n",
    "                                                                  uci_data.climate['target'],\n",
    "                                                                  test_size=0.40,\n",
    "                                                                  random_state=42,\n",
    "                                                                  stratify=uci_data.climate['target'])\n",
    "test_ucibest(climate_tr, climate_ts, climate_y_tr, climate_y_ts, climate_best, \n",
    "             preprocess='scaled+umap', n_jobs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `banknote` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banknote_best = {'s': best_scaledumap['banknote'][0][0],\n",
    "               'c': best_scaledumap['banknote'][0][1],\n",
    "               'nclust': best_scaledumap['banknote'][0][2]}\n",
    "banknote_tr, banknote_ts, banknote_y_tr, banknote_y_ts = train_test_split(uci_data.banknote['data'],\n",
    "                                                                  uci_data.banknote['target'],\n",
    "                                                                  test_size=0.40,\n",
    "                                                                  random_state=42,\n",
    "                                                                  stratify=uci_data.banknote['target'])\n",
    "test_ucibest(banknote_tr, banknote_ts, banknote_y_tr, banknote_y_ts, banknote_best, \n",
    "             preprocess='scaled+umap', n_jobs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `parkinsons` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parkinsons_best = {'s': best_scaledumap['parkinsons'][0][0],\n",
    "               'c': best_scaledumap['parkinsons'][0][1],\n",
    "               'nclust': best_scaledumap['parkinsons'][0][2]}\n",
    "parkinsons_tr, parkinsons_ts, parkinsons_y_tr, parkinsons_y_ts = train_test_split(uci_data.parkinsons['data'],\n",
    "                                                                  uci_data.parkinsons['target'],\n",
    "                                                                  test_size=0.40,\n",
    "                                                                  random_state=42,\n",
    "                                                                  stratify=uci_data.parkinsons['target'])\n",
    "test_ucibest(parkinsons_tr, parkinsons_ts, parkinsons_y_tr, parkinsons_y_ts, parkinsons_best, \n",
    "             preprocess='scaled+umap', n_jobs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `yeast` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeast_best = {'s': best_scaledumap['yeast'][0][0],\n",
    "               'c': best_scaledumap['yeast'][0][1],\n",
    "               'nclust': best_scaledumap['yeast'][0][2]}\n",
    "yeast_tr, yeast_ts, yeast_y_tr, yeast_y_ts = train_test_split(uci_data.yeast['data'],\n",
    "                                                                  uci_data.yeast['target'],\n",
    "                                                                  test_size=0.40,\n",
    "                                                                  random_state=42,\n",
    "                                                                  stratify=uci_data.yeast['target'])\n",
    "test_ucibest(yeast_tr, yeast_ts, yeast_y_tr, yeast_y_ts, yeast_best, \n",
    "             preprocess='scaled+umap', n_jobs=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `urban` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_best = {'s': best_scaledumap['urban'][0][0],\n",
    "               'c': best_scaledumap['urban'][0][1],\n",
    "               'nclust': best_scaledumap['urban'][0][2]}\n",
    "urban_tr, urban_ts, urban_y_tr, urban_y_ts = train_test_split(uci_data.urban['data'],\n",
    "                                                                  uci_data.urban['target'],\n",
    "                                                                  test_size=0.40,\n",
    "                                                                  random_state=42,\n",
    "                                                                  stratify=uci_data.urban['target'])\n",
    "test_ucibest(urban_tr, urban_ts, urban_y_tr, urban_y_ts, urban_best, \n",
    "             preprocess='scaled+umap', n_jobs=7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
